{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMLMElX4oFw"
      },
      "source": [
        "# Anti Money Laundering Detection with GNN node classification\n",
        "### This notenook includes GNN model training and dataset implementation with PyG library. In this example, we used HI-Small_Trans.csv as our dataset for training and testing.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO0ktS0aC0U5",
        "outputId": "706dca99-3e3b-484d-8d98-fdd0bba51ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.2)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pnAUP0sEPQS",
        "outputId": "2bbf07d9-8d35-430c-91a8-2e26bd70ca99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.4.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.4.0+pt20cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m649.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-1VXn234xrC",
        "outputId": "2916863e-d2f0-4447-fc6f-87d001d3d568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-07T05:03:44.040372Z",
          "iopub.status.busy": "2023-10-07T05:03:44.039793Z",
          "iopub.status.idle": "2023-10-07T05:03:58.147392Z",
          "shell.execute_reply": "2023-10-07T05:03:58.146038Z",
          "shell.execute_reply.started": "2023-10-07T05:03:44.040343Z"
        },
        "trusted": true,
        "id": "WRIq6B5Q4oFx"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "from typing import Callable, Optional\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/HI-Small_Trans.csv'\n",
        "df = pd.read_csv(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhH-prk_4oFy"
      },
      "source": [
        "# Data visualization and possible feature engineering\n",
        "Let's look into the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:33:22.849494Z",
          "iopub.status.busy": "2023-10-07T05:33:22.849049Z",
          "iopub.status.idle": "2023-10-07T05:33:22.867501Z",
          "shell.execute_reply": "2023-10-07T05:33:22.866198Z",
          "shell.execute_reply.started": "2023-10-07T05:33:22.849448Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NAgCJzJ4oFy",
        "outputId": "9b5e5913-eb1d-4706-e2ea-ae88f5ee6ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
            "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
            "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
            "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
            "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
            "\n",
            "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "0          3697.34          US Dollar      3697.34        US Dollar   \n",
            "1             0.01          US Dollar         0.01        US Dollar   \n",
            "2         14675.57          US Dollar     14675.57        US Dollar   \n",
            "3          2806.97          US Dollar      2806.97        US Dollar   \n",
            "4         36682.97          US Dollar     36682.97        US Dollar   \n",
            "\n",
            "  Payment Format  Is Laundering  \n",
            "0   Reinvestment              0  \n",
            "1         Cheque              0  \n",
            "2   Reinvestment              0  \n",
            "3   Reinvestment              0  \n",
            "4   Reinvestment              0  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYk4bSDL4oFz"
      },
      "source": [
        "After the viewing the dataframe, we suggest that we can extract all accounts from receiver and payer among all transcation for sorting the suspicious accounts. We can transform the whole dataset into node classification problem by considering accounts as nodes while transcation as edges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPWrKE8U4oFz"
      },
      "source": [
        "The object columns should be encoded into classes with sklearn LabelEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:36:52.790986Z",
          "iopub.status.busy": "2023-10-07T05:36:52.790429Z",
          "iopub.status.idle": "2023-10-07T05:36:52.797831Z",
          "shell.execute_reply": "2023-10-07T05:36:52.796721Z",
          "shell.execute_reply.started": "2023-10-07T05:36:52.790952Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6NxIjmj4oF0",
        "outputId": "a3b4f626-acba-47e0-af81-92fd1cd8eb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp              object\n",
            "From Bank               int64\n",
            "Account                object\n",
            "To Bank                 int64\n",
            "Account.1              object\n",
            "Amount Received       float64\n",
            "Receiving Currency     object\n",
            "Amount Paid           float64\n",
            "Payment Currency       object\n",
            "Payment Format         object\n",
            "Is Laundering           int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSTw4rHV4oF0"
      },
      "source": [
        "Check if there are any null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:40:11.526713Z",
          "iopub.status.busy": "2023-10-07T05:40:11.526397Z",
          "iopub.status.idle": "2023-10-07T05:40:12.913554Z",
          "shell.execute_reply": "2023-10-07T05:40:12.912335Z",
          "shell.execute_reply.started": "2023-10-07T05:40:11.526687Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUds_OYd4oF0",
        "outputId": "5d2ccd07-60db-47e8-b72e-711d218c44d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp             0\n",
            "From Bank             0\n",
            "Account               0\n",
            "To Bank               0\n",
            "Account.1             0\n",
            "Amount Received       0\n",
            "Receiving Currency    0\n",
            "Amount Paid           0\n",
            "Payment Currency      0\n",
            "Payment Format        0\n",
            "Is Laundering         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RlbCH6d4oF0"
      },
      "source": [
        "There are two columns representing paid and received amount of each transcation, wondering if it is necessary to split the amount into two columns when they shared the same value, unless there are transcation fee/transcation between different currency. Let's find out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:45:40.568327Z",
          "iopub.status.busy": "2023-10-07T05:45:40.567898Z",
          "iopub.status.idle": "2023-10-07T05:45:40.594713Z",
          "shell.execute_reply": "2023-10-07T05:45:40.593358Z",
          "shell.execute_reply.started": "2023-10-07T05:45:40.568296Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHwkMhan4oF0",
        "outputId": "1e30b213-7cfe-4ca2-f0c9-bf3bcc727f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount Received equals to Amount Paid:\n",
            "False\n",
            "Receiving Currency equals to Payment Currency:\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print('Amount Received equals to Amount Paid:')\n",
        "print(df['Amount Received'].equals(df['Amount Paid']))\n",
        "print('Receiving Currency equals to Payment Currency:')\n",
        "print(df['Receiving Currency'].equals(df['Payment Currency']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hja-J56o4oF1"
      },
      "source": [
        "It seens involved the transcations between different currency, let's print it out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:46:16.614934Z",
          "iopub.status.busy": "2023-10-07T05:46:16.614531Z",
          "iopub.status.idle": "2023-10-07T05:46:17.289425Z",
          "shell.execute_reply": "2023-10-07T05:46:17.288314Z",
          "shell.execute_reply.started": "2023-10-07T05:46:16.614907Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KAnDDKr4oF1",
        "outputId": "8a8d4b30-eb64-4420-ae68-16548a755361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "1173     2022/09/01 00:22       1362  80030A870     1362  80030A870   \n",
            "7156     2022/09/01 00:28      11318  800C51010    11318  800C51010   \n",
            "7925     2022/09/01 00:12        795  800D98770      795  800D98770   \n",
            "8467     2022/09/01 00:01       1047  800E92CF0     1047  800E92CF0   \n",
            "11529    2022/09/01 00:22      11157  80135FFC0    11157  80135FFC0   \n",
            "...                   ...        ...        ...      ...        ...   \n",
            "5078167  2022/09/10 23:30      23537  803949A90    23537  803949A90   \n",
            "5078234  2022/09/10 23:59      16163  803638A90    16163  803638A90   \n",
            "5078236  2022/09/10 23:55      16163  803638A90    16163  803638A90   \n",
            "5078316  2022/09/10 23:44     215064  808F06E11   215064  808F06E10   \n",
            "5078318  2022/09/10 23:45     215064  808F06E11   215064  808F06E10   \n",
            "\n",
            "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "1173           52.110000               Euro        61.06        US Dollar   \n",
            "7156           76.060000               Euro        89.12        US Dollar   \n",
            "7925           17.690000  Australian Dollar        12.52        US Dollar   \n",
            "8467           19.430000               Euro        22.77        US Dollar   \n",
            "11529          98.340000               Euro       115.24        US Dollar   \n",
            "...                  ...                ...          ...              ...   \n",
            "5078167     26421.500000             Shekel      7823.96        US Dollar   \n",
            "5078234     47517.490000        Saudi Riyal     12667.62        US Dollar   \n",
            "5078236     11329.850000        Saudi Riyal      3020.41        US Dollar   \n",
            "5078316         0.000006            Bitcoin         0.07        US Dollar   \n",
            "5078318         0.000004            Bitcoin         0.05        US Dollar   \n",
            "\n",
            "        Payment Format  Is Laundering  \n",
            "1173               ACH              0  \n",
            "7156               ACH              0  \n",
            "7925               ACH              0  \n",
            "8467               ACH              0  \n",
            "11529              ACH              0  \n",
            "...                ...            ...  \n",
            "5078167            ACH              0  \n",
            "5078234            ACH              0  \n",
            "5078236            ACH              0  \n",
            "5078316            ACH              0  \n",
            "5078318           Wire              0  \n",
            "\n",
            "[72158 rows x 11 columns]\n",
            "---------------------------------------------------------------------------\n",
            "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "1173     2022/09/01 00:22       1362  80030A870     1362  80030A870   \n",
            "7156     2022/09/01 00:28      11318  800C51010    11318  800C51010   \n",
            "7925     2022/09/01 00:12        795  800D98770      795  800D98770   \n",
            "8467     2022/09/01 00:01       1047  800E92CF0     1047  800E92CF0   \n",
            "11529    2022/09/01 00:22      11157  80135FFC0    11157  80135FFC0   \n",
            "...                   ...        ...        ...      ...        ...   \n",
            "5078167  2022/09/10 23:30      23537  803949A90    23537  803949A90   \n",
            "5078234  2022/09/10 23:59      16163  803638A90    16163  803638A90   \n",
            "5078236  2022/09/10 23:55      16163  803638A90    16163  803638A90   \n",
            "5078316  2022/09/10 23:44     215064  808F06E11   215064  808F06E10   \n",
            "5078318  2022/09/10 23:45     215064  808F06E11   215064  808F06E10   \n",
            "\n",
            "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "1173           52.110000               Euro        61.06        US Dollar   \n",
            "7156           76.060000               Euro        89.12        US Dollar   \n",
            "7925           17.690000  Australian Dollar        12.52        US Dollar   \n",
            "8467           19.430000               Euro        22.77        US Dollar   \n",
            "11529          98.340000               Euro       115.24        US Dollar   \n",
            "...                  ...                ...          ...              ...   \n",
            "5078167     26421.500000             Shekel      7823.96        US Dollar   \n",
            "5078234     47517.490000        Saudi Riyal     12667.62        US Dollar   \n",
            "5078236     11329.850000        Saudi Riyal      3020.41        US Dollar   \n",
            "5078316         0.000006            Bitcoin         0.07        US Dollar   \n",
            "5078318         0.000004            Bitcoin         0.05        US Dollar   \n",
            "\n",
            "        Payment Format  Is Laundering  \n",
            "1173               ACH              0  \n",
            "7156               ACH              0  \n",
            "7925               ACH              0  \n",
            "8467               ACH              0  \n",
            "11529              ACH              0  \n",
            "...                ...            ...  \n",
            "5078167            ACH              0  \n",
            "5078234            ACH              0  \n",
            "5078236            ACH              0  \n",
            "5078316            ACH              0  \n",
            "5078318           Wire              0  \n",
            "\n",
            "[72170 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
        "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
        "print(not_equal1)\n",
        "print('---------------------------------------------------------------------------')\n",
        "print(not_equal2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlNFZdgM4oF1"
      },
      "source": [
        "The size of two df shows that there are transcation fee and transcation between different currency, we cannot combine/drop the amount columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUWOwA2y4oF1"
      },
      "source": [
        "As we are going to encode the columns, we have to make sure that the classes of same attribute are aligned.\n",
        "Let's check if the list of Receiving Currency and Payment Currency are the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:51:06.994519Z",
          "iopub.status.busy": "2023-10-07T05:51:06.994058Z",
          "iopub.status.idle": "2023-10-07T05:51:07.455980Z",
          "shell.execute_reply": "2023-10-07T05:51:07.454722Z",
          "shell.execute_reply.started": "2023-10-07T05:51:06.994490Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V_dHar-4oF1",
        "outputId": "c5875a21-2488-4fa0-c53e-a0c31363b15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
            "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
          ]
        }
      ],
      "source": [
        "print(sorted(df['Receiving Currency'].unique()))\n",
        "print(sorted(df['Payment Currency'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynAslwzs4oF1"
      },
      "source": [
        "# Data Preprocessing\n",
        "### We will show the functions used in the PyG dataset first, dataset and model training will be provided in bottom section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsq3PYse4oF1"
      },
      "source": [
        "In the data preprocessing, we perform below transformation:  \n",
        "1. Transform the Timestamp with min max normalization.  \n",
        "2. Create unique ID for each account by adding bank code with account number.  \n",
        "3. Create receiving_df with the information of receiving accounts, received amount and currency\n",
        "4. Create paying_df with the information of payer accounts, paid amount and currency\n",
        "5. Create a list of currency used among all transactions\n",
        "6. Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:53:11.423289Z",
          "iopub.status.busy": "2023-10-07T05:53:11.422843Z",
          "iopub.status.idle": "2023-10-07T05:53:11.432504Z",
          "shell.execute_reply": "2023-10-07T05:53:11.431355Z",
          "shell.execute_reply.started": "2023-10-07T05:53:11.423245Z"
        },
        "trusted": true,
        "id": "QCudCUwa4oF1"
      },
      "outputs": [],
      "source": [
        "def df_label_encoder(df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "def preprocess(df):\n",
        "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6w--sj94oF2"
      },
      "source": [
        "Let's have a look of processed df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:53:15.266963Z",
          "iopub.status.busy": "2023-10-07T05:53:15.266592Z",
          "iopub.status.idle": "2023-10-07T05:53:56.218064Z",
          "shell.execute_reply": "2023-10-07T05:53:56.216975Z",
          "shell.execute_reply.started": "2023-10-07T05:53:15.266935Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSo-brxx4oF2",
        "outputId": "4f55fa59-920f-4497-e024-09c7f61e1175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Timestamp  From Bank          Account  To Bank        Account.1  \\\n",
            "4278714   0.456320      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "2798190   0.285018      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "2798191   0.284233      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "3918769   0.417079      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "213094    0.000746      10057  10057_803A115E0    10057  10057_803A115E0   \n",
            "\n",
            "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
            "4278714        787197.11                  13    787197.11                13   \n",
            "2798190        787197.11                  13    787197.11                13   \n",
            "2798191        681262.19                  13    681262.19                13   \n",
            "3918769        681262.19                  13    681262.19                13   \n",
            "213094         146954.27                  13    146954.27                13   \n",
            "\n",
            "         Payment Format  Is Laundering  \n",
            "4278714               3              0  \n",
            "2798190               3              0  \n",
            "2798191               4              0  \n",
            "3918769               4              0  \n",
            "213094                5              0  \n"
          ]
        }
      ],
      "source": [
        "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDilSX_l4oF2"
      },
      "source": [
        "paying df and receiving df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:25.918744Z",
          "iopub.status.busy": "2023-10-07T05:57:25.918280Z",
          "iopub.status.idle": "2023-10-07T05:57:25.929797Z",
          "shell.execute_reply": "2023-10-07T05:57:25.928625Z",
          "shell.execute_reply.started": "2023-10-07T05:57:25.918708Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFWSgHkO4oF2",
        "outputId": "9db4c4ba-b990-4121-b1e2-d9e1fffdab7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Account  Amount Received  Receiving Currency\n",
            "4278714  29467_803E020C0        787197.11                  13\n",
            "2798190  29467_803E020C0        787197.11                  13\n",
            "2798191  29467_803E020C0        681262.19                  13\n",
            "3918769  29467_803E020C0        681262.19                  13\n",
            "213094   10057_803A115E0        146954.27                  13\n",
            "                 Account  Amount Paid  Payment Currency\n",
            "4278714  10057_803A115E0    787197.11                13\n",
            "2798190  10057_803A115E0    787197.11                13\n",
            "2798191  10057_803A115E0    681262.19                13\n",
            "3918769  10057_803A115E0    681262.19                13\n",
            "213094   10057_803A115E0    146954.27                13\n"
          ]
        }
      ],
      "source": [
        "print(receiving_df.head())\n",
        "print(paying_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH97-bjj4oF2"
      },
      "source": [
        "currency_ls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:28.907031Z",
          "iopub.status.busy": "2023-10-07T05:57:28.906667Z",
          "iopub.status.idle": "2023-10-07T05:57:28.913761Z",
          "shell.execute_reply": "2023-10-07T05:57:28.912327Z",
          "shell.execute_reply.started": "2023-10-07T05:57:28.907004Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsRqwex64oF2",
        "outputId": "0e25d85c-969d-4576-e614-18cb4b4a1b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ],
      "source": [
        "print(currency_ls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpGagnqs4oF2"
      },
      "source": [
        "We would like to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.  \n",
        "In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with 'Is Laundering' == 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:31.850839Z",
          "iopub.status.busy": "2023-10-07T05:57:31.850459Z",
          "iopub.status.idle": "2023-10-07T05:57:31.858990Z",
          "shell.execute_reply": "2023-10-07T05:57:31.857826Z",
          "shell.execute_reply.started": "2023-10-07T05:57:31.850810Z"
        },
        "trusted": true,
        "id": "122-Bw3H4oF3"
      },
      "outputs": [],
      "source": [
        "def get_all_account(df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering']==1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLckImMQ4oF3"
      },
      "source": [
        "Take a look of the account list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:34.379521Z",
          "iopub.status.busy": "2023-10-07T05:57:34.378456Z",
          "iopub.status.idle": "2023-10-07T05:57:41.317058Z",
          "shell.execute_reply": "2023-10-07T05:57:41.316062Z",
          "shell.execute_reply.started": "2023-10-07T05:57:34.379481Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFfTc8kh4oF3",
        "outputId": "7fadb91b-06af-4e5a-ccb3-d3f5902c8b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Account   Bank  Is Laundering\n",
            "0  10057_803A115E0  10057              0\n",
            "1  10057_803AA8E90  10057              0\n",
            "2  10057_803AAB430  10057              0\n",
            "3  10057_803AACE20  10057              0\n",
            "4  10057_803AB4F70  10057              0\n"
          ]
        }
      ],
      "source": [
        "accounts = get_all_account(df)\n",
        "print(accounts.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-G6iCVx4oF4"
      },
      "source": [
        "# Node features\n",
        "[For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:43.694369Z",
          "iopub.status.busy": "2023-10-07T05:57:43.693958Z",
          "iopub.status.idle": "2023-10-07T05:57:43.701141Z",
          "shell.execute_reply": "2023-10-07T05:57:43.699901Z",
          "shell.execute_reply.started": "2023-10-07T05:57:43.694334Z"
        },
        "trusted": true,
        "id": "QoC4YA5V4oF4"
      },
      "outputs": [],
      "source": [
        "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
        "    for i in currency_ls:\n",
        "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "    accounts = accounts.fillna(0)\n",
        "    return accounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4H7yXBI4oF4"
      },
      "source": [
        "Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:45.915808Z",
          "iopub.status.busy": "2023-10-07T05:57:45.915112Z",
          "iopub.status.idle": "2023-10-07T05:57:45.926442Z",
          "shell.execute_reply": "2023-10-07T05:57:45.924963Z",
          "shell.execute_reply.started": "2023-10-07T05:57:45.915734Z"
        },
        "trusted": true,
        "id": "XF9brY7l4oF4"
      },
      "outputs": [],
      "source": [
        "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
        "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = df_label_encoder(node_df,['Bank'])\n",
        "#         node_df = torch.from_numpy(node_df.values).to(torch.float)  # comment for visualization\n",
        "        return node_df, node_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bsdDb3L4oF4"
      },
      "source": [
        "Take a look of node_df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:57:48.258031Z",
          "iopub.status.busy": "2023-10-07T05:57:48.257639Z",
          "iopub.status.idle": "2023-10-07T05:57:56.275657Z",
          "shell.execute_reply": "2023-10-07T05:57:56.274417Z",
          "shell.execute_reply.started": "2023-10-07T05:57:48.257999Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc5VRbNb4oF4",
        "outputId": "3a416407-d225-48b2-b9ae-85cf50ef05e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
            "0     2         0.0         0.0         0.0         0.0         0.0   \n",
            "1     2         0.0         0.0         0.0         0.0         0.0   \n",
            "2     2         0.0         0.0         0.0         0.0         0.0   \n",
            "3     2         0.0         0.0         0.0         0.0         0.0   \n",
            "4     2         0.0         0.0         0.0         0.0         0.0   \n",
            "\n",
            "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
            "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "\n",
            "   avg paid 11   avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
            "0          0.0   1922.000000          0.0          0.0             0.0   \n",
            "1          0.0    480.223333          0.0          0.0             0.0   \n",
            "2          0.0  14675.570000          0.0          0.0             0.0   \n",
            "3          0.0  37340.843333          0.0          0.0             0.0   \n",
            "4          0.0  49649.409677          0.0          0.0             0.0   \n",
            "\n",
            "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
            "0             0.0              0.0              0.0       330.166429   \n",
            "1             0.0              0.0              0.0       119.992000   \n",
            "2             0.0              0.0              0.0     14675.570000   \n",
            "3             0.0              0.0              0.0       756.486190   \n",
            "4             0.0              0.0              0.0      3120.573333   \n",
            "\n",
            "   avg received 13  avg received 14  \n",
            "0              0.0              0.0  \n",
            "1              0.0              0.0  \n",
            "2              0.0              0.0  \n",
            "3              0.0              0.0  \n",
            "4              0.0              0.0  \n"
          ]
        }
      ],
      "source": [
        "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
        "print(node_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWdKFEpK4oF5"
      },
      "source": [
        "# Edge features\n",
        "In terms of edge features, we would like to conside each transcation as edges.  \n",
        "For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]  \n",
        "For edge attributes, we used 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:58:06.006625Z",
          "iopub.status.busy": "2023-10-07T05:58:06.006227Z",
          "iopub.status.idle": "2023-10-07T05:58:06.015211Z",
          "shell.execute_reply": "2023-10-07T05:58:06.014356Z",
          "shell.execute_reply.started": "2023-10-07T05:58:06.006594Z"
        },
        "trusted": true,
        "id": "UJ0tQRiQ4oF5"
      },
      "outputs": [],
      "source": [
        "def get_edge_df(accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "#         edge_attr = torch.from_numpy(df.values).to(torch.float)  # comment for visualization\n",
        "\n",
        "        edge_attr = df  # for visualization\n",
        "        return edge_attr, edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUJXd5-E4oF5"
      },
      "source": [
        "edge_attr:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T06:00:02.820037Z",
          "iopub.status.busy": "2023-10-07T06:00:02.819644Z",
          "iopub.status.idle": "2023-10-07T06:00:07.880960Z",
          "shell.execute_reply": "2023-10-07T06:00:07.879754Z",
          "shell.execute_reply.started": "2023-10-07T06:00:02.820005Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiHZNZgQ4oF5",
        "outputId": "b74a4520-c7d8-4a67-fded-e75024224136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
            "4278714   0.456320        787197.11                  13    787197.11   \n",
            "2798190   0.285018        787197.11                  13    787197.11   \n",
            "2798191   0.284233        681262.19                  13    681262.19   \n",
            "3918769   0.417079        681262.19                  13    681262.19   \n",
            "213094    0.000746        146954.27                  13    146954.27   \n",
            "\n",
            "         Payment Currency  Payment Format  \n",
            "4278714                13               3  \n",
            "2798190                13               3  \n",
            "2798191                13               4  \n",
            "3918769                13               4  \n",
            "213094                 13               5  \n"
          ]
        }
      ],
      "source": [
        "edge_attr, edge_index = get_edge_df(accounts, df)\n",
        "print(edge_attr.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdpVucbF4oF6"
      },
      "source": [
        "edge_index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:58:16.265617Z",
          "iopub.status.busy": "2023-10-07T05:58:16.265045Z",
          "iopub.status.idle": "2023-10-07T05:58:16.274597Z",
          "shell.execute_reply": "2023-10-07T05:58:16.273471Z",
          "shell.execute_reply.started": "2023-10-07T05:58:16.265571Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYWgcjbU4oF6",
        "outputId": "470e6f93-3871-4e27-b679-4751436fa4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[     0,      0,      0,  ..., 496997, 496997, 496998],\n",
            "        [299458, 299458, 299458,  ..., 496997, 496997, 496998]])\n"
          ]
        }
      ],
      "source": [
        "print(edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRXzl23M4oF6"
      },
      "source": [
        "# Final code\n",
        "### Below we will show the final code for model.py, train.py and dataset.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV4z_rJ04oF7"
      },
      "source": [
        "# Model Architecture\n",
        "In this section, we used Graph Attention Networks as our backbone model.  \n",
        "The model built with two GATConv layers followed by a linear layer with sigmoid outout for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "hTVjKr7F4oF7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GATConv, Linear\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
        "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = self.lin(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViA8C7YK4oF7"
      },
      "source": [
        "# PyG InMemoryDataset\n",
        "Finally we can build the dataset with above functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-diwShRL4oF7",
        "outputId": "184b7e47-7952-49dc-ef91-3c8c55a7d204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN/raw/HI-Small_Trans.csv\n",
            "/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN/processed/pre_transform.pt\n",
            "/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN/processed/pre_filter.pt\n",
            "/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN/processed/data.pt\n",
            "Data(x=[515088, 31], edge_index=[2, 5078345], edge_attr=[5078345, 6], y=[515088])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from sklearn import preprocessing\n",
        "from typing import Callable, Optional\n",
        "\n",
        "class AMLtoGraph(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root: str, edge_window_size: int = 10,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 pre_transform: Optional[Callable] = None):\n",
        "        self.edge_window_size = edge_window_size\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        # Kiểm tra và tải tệp data.pt nếu tồn tại\n",
        "        if os.path.exists(self.processed_paths[0]):\n",
        "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "        else:\n",
        "            self.data, self.slices = None, None\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self) -> str:\n",
        "        # Chỉnh sửa đường dẫn này để khớp với vị trí thực tế của tệp CSV\n",
        "        return 'HI-Small_Trans.csv'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> str:\n",
        "        return 'data.pt'\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self) -> int:\n",
        "        return self._data.edge_index.max().item() + 1\n",
        "\n",
        "    def df_label_encoder(self, df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        df = self.df_label_encoder(df, ['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp'] - df['Timestamp'].min()) / (df['Timestamp'].max() - df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls\n",
        "\n",
        "    def get_all_account(self, df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering'] == 1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df\n",
        "\n",
        "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid ' + str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "            accounts['avg received ' + str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "        accounts = accounts.fillna(0)\n",
        "        return accounts\n",
        "\n",
        "    def get_edge_df(self, accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
        "        return edge_attr, edge_index\n",
        "\n",
        "    def get_node_attr(self, currency_ls, paying_df, receiving_df, accounts):\n",
        "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = self.df_label_encoder(node_df, ['Bank'])\n",
        "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
        "        return node_df, node_label\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
        "        accounts = self.get_all_account(df)\n",
        "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df, receiving_df, accounts)\n",
        "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
        "\n",
        "        data = Data(x=node_attr,\n",
        "                    edge_index=edge_index,\n",
        "                    y=node_label,\n",
        "                    edge_attr=edge_attr\n",
        "                    )\n",
        "\n",
        "        data_list = [data]\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "# Đảm bảo rằng bạn đã gắn kết Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Cập nhật đường dẫn tới thư mục đúng\n",
        "root_dir = '/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN/'\n",
        "\n",
        "# Kiểm tra và tạo thư mục processed nếu chưa tồn tại\n",
        "processed_dir = os.path.join(root_dir, 'processed')\n",
        "if not os.path.exists(processed_dir):\n",
        "    os.makedirs(processed_dir)\n",
        "\n",
        "# Kiểm tra các tệp trong thư mục để xác minh đường dẫn và tệp tồn tại\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n",
        "\n",
        "# Tạo đối tượng dataset và chạy phương thức process để tạo tệp data.pt\n",
        "dataset = AMLtoGraph(root=root_dir)\n",
        "dataset.process()\n",
        "\n",
        "# Sau khi tạo tệp, bạn có thể tải nó lại\n",
        "dataset = AMLtoGraph(root=root_dir)\n",
        "data = dataset[0]\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nowJMxuy4oF7"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Định dạng của đoạn này là mã\n",
        "```\n",
        "\n",
        "# Model Training\n",
        "As we cannot create folder in kaggle, please follow the instructions in https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN before you start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVRfkPwm4oF7",
        "outputId": "a8fe80fe-83ec-4222-ffc0-9fa841537058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 4161.4352\n",
            "accuracy: 0.97117220408265\n",
            "Epoch: 001, Loss: 2866.0191\n",
            "accuracy: 0.9719523738355004\n",
            "Epoch: 002, Loss: 2434.5939\n",
            "accuracy: 0.9720840766616502\n",
            "Epoch: 003, Loss: 2149.1657\n",
            "accuracy: 0.972301681434452\n",
            "Epoch: 004, Loss: 2041.0376\n",
            "accuracy: 0.9722171021496002\n",
            "Epoch: 005, Loss: 1985.2575\n",
            "accuracy: 0.9722986306284758\n",
            "Epoch: 006, Loss: 1968.6619\n",
            "accuracy: 0.9721148289124932\n",
            "Epoch: 007, Loss: 1924.9502\n",
            "accuracy: 0.972266390194544\n",
            "Epoch: 008, Loss: 1908.8533\n",
            "accuracy: 0.9721498428135136\n",
            "Epoch: 009, Loss: 1885.7342\n",
            "accuracy: 0.9723248886719333\n",
            "Epoch: 010, Loss: 1875.8962\n",
            "accuracy: 0.9723573265293919\n",
            "Epoch: 011, Loss: 1846.9660\n",
            "accuracy: 0.9722896309104408\n",
            "Epoch: 012, Loss: 1844.2273\n",
            "accuracy: 0.9724701602252622\n",
            "Epoch: 013, Loss: 1820.9419\n",
            "accuracy: 0.9724804926903644\n",
            "Epoch: 014, Loss: 1794.8081\n",
            "accuracy: 0.972545541515526\n",
            "Epoch: 015, Loss: 1801.2183\n",
            "accuracy: 0.9725619933534954\n",
            "Epoch: 016, Loss: 1769.6606\n",
            "accuracy: 0.9726152941938248\n",
            "Epoch: 017, Loss: 1759.2297\n",
            "accuracy: 0.972602398473427\n",
            "Epoch: 018, Loss: 1744.5117\n",
            "accuracy: 0.9726102492287911\n",
            "Epoch: 019, Loss: 1748.7054\n",
            "accuracy: 0.9725484724513033\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dataset = AMLtoGraph('/content/drive/My Drive/AntiMoneyLaunderingDetectionWithGNN')\n",
        "data = dataset[0]\n",
        "epoch = 20\n",
        "\n",
        "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
        "data = split(data)\n",
        "\n",
        "train_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.train_mask,\n",
        ")\n",
        "\n",
        "test_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.val_mask,\n",
        ")\n",
        "\n",
        "for i in range(epoch):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data.to(device)\n",
        "        pred = model(data.x, data.edge_index, data.edge_attr)\n",
        "        ground_truth = data.y\n",
        "        loss = criterion(pred, ground_truth.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss)\n",
        "    if epoch%10 == 0:\n",
        "        print(f\"Epoch: {i:03d}, Loss: {total_loss:.4f}\")\n",
        "        model.eval()\n",
        "        acc = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for test_data in test_loader:\n",
        "                test_data.to(device)\n",
        "                pred = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
        "                ground_truth = test_data.y\n",
        "                correct = (pred == ground_truth.unsqueeze(1)).sum().item()\n",
        "                total += len(ground_truth)\n",
        "                acc += correct\n",
        "            acc = acc/total\n",
        "            print('accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Fp1KKJ4oF8"
      },
      "source": [
        "# Future Work\n",
        "In this notebook, we performed the node classification with GAT and the result accuracy looks satisfied.  \n",
        "However, it may due to highly imbalance data of the dataset. It is suggested that balance the class of 1 and 0 in the data preprocessing. It is expected that the accuracy will dropped a little bit after balancing the data.  We will keep exploring to see if there are any other models give better performance, such as other traditional regression/classifier model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1vXhEua4oF8"
      },
      "source": [
        "## Reference\n",
        "Some of the feature engineering of this repo are referenced to below papers, highly recommend to read:\n",
        "1. [Weber, M., Domeniconi, G., Chen, J., Weidele, D. K. I., Bellei, C., Robinson, T., & Leiserson, C. E. (2019). Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. arXiv preprint arXiv:1908.02591.](https://arxiv.org/pdf/1908.02591.pdf)\n",
        "2. [Johannessen, F., & Jullum, M. (2023). Finding Money Launderers Using Heterogeneous Graph Neural Networks. arXiv preprint arXiv:2307.13499.](https://arxiv.org/pdf/2307.13499.pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}